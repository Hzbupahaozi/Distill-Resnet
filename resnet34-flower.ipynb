{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 7019145,
     "sourceType": "datasetVersion",
     "datasetId": 4036075
    }
   ],
   "dockerImageVersionId": 30588,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2023-11-25T14:04:08.597255Z",
     "iopub.execute_input": "2023-11-25T14:04:08.597537Z",
     "iopub.status.idle": "2023-11-25T14:04:14.485022Z",
     "shell.execute_reply.started": "2023-11-25T14:04:08.597513Z",
     "shell.execute_reply": "2023-11-25T14:04:14.483883Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "execution_count": 1,
     "output_type": "execute_result",
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "epochs = 50\n",
    "batch_size = 16\n",
    "save_steps = 10\n",
    "num_workers = 4\n",
    "\n",
    "lr = 0.001\n",
    "lr_step_size = 40"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-25T14:04:14.487480Z",
     "iopub.execute_input": "2023-11-25T14:04:14.487849Z",
     "iopub.status.idle": "2023-11-25T14:04:14.492447Z",
     "shell.execute_reply.started": "2023-11-25T14:04:14.487823Z",
     "shell.execute_reply": "2023-11-25T14:04:14.491436Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "def read_split_data(root, val_rate=0.2):\n",
    "    \n",
    "    assert os.path.exists(root), \"dataset root: {} does not exist.\".format(root)\n",
    "\n",
    "    flower_class = [cla for cla in os.listdir(root) if os.path.isdir(os.path.join(root, cla))]\n",
    "    flower_class.sort()\n",
    "    class_indices = dict((k, v) for v, k in enumerate(flower_class))\n",
    "    print(class_indices) \n",
    "\n",
    "    train_images_path = []\n",
    "    train_images_label = []\n",
    "    val_images_path = []\n",
    "    val_images_label = []\n",
    "    every_class_num = []\n",
    "   \n",
    "    for cla in flower_class:\n",
    "        cla_path = os.path.join(root, cla)\n",
    "        images = [os.path.join(root, cla, i) for i in os.listdir(cla_path)]\n",
    "        images.sort()\n",
    "        image_class = class_indices[cla]\n",
    "        \n",
    "        every_class_num.append(len(images))\n",
    "        val_path = random.sample(images, k=int(len(images) * val_rate))\n",
    "        \n",
    "        # 划分训练集 和 验证集\n",
    "        for img_path in images:\n",
    "            if img_path in val_path:  \n",
    "                val_images_path.append(img_path)\n",
    "                val_images_label.append(image_class)\n",
    "            else:  \n",
    "                train_images_path.append(img_path)\n",
    "                train_images_label.append(image_class)\n",
    "\n",
    "    print(\"{} images were found in the dataset.\".format(sum(every_class_num)))\n",
    "    print(\"{} images for training.\".format(len(train_images_path)))\n",
    "    print(\"{} images for validation.\".format(len(val_images_path)))\n",
    "    assert len(train_images_path) > 0, \"number of training images must greater than 0.\"\n",
    "    assert len(val_images_path) > 0, \"number of validation images must greater than 0.\"\n",
    "\n",
    "    return train_images_path, train_images_label, val_images_path, val_images_label\n",
    "\n",
    "\n",
    "class MyDataSet(Dataset):\n",
    "    \"\"\"自定义数据集\"\"\"\n",
    "\n",
    "    def __init__(self, images_path, images_class, transform=None):\n",
    "        self.images_path = images_path\n",
    "        self.images_class = images_class\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_path)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img = Image.open(self.images_path[item])\n",
    "        label = self.images_class[item]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return torch.as_tensor(img), torch.as_tensor(label)\n",
    "\n",
    "\n",
    "data_root = \"/kaggle/input/flowers/flower_photos\"\n",
    "train_images_path, train_images_label, val_images_path, val_images_label = read_split_data(data_root)\n",
    "\n",
    "# =============================== Transform ===============================\n",
    "img_size = 224\n",
    "train_transform = transforms.Compose([transforms.RandomResizedCrop(img_size),\n",
    "                                        transforms.RandomHorizontalFlip(),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "val_transform = transforms.Compose([transforms.Resize(int(img_size * 1.143)),\n",
    "                                      transforms.CenterCrop(img_size),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "# =============================== DataSet ===============================\n",
    "\n",
    "train_dataset = MyDataSet(images_path=train_images_path,\n",
    "                          images_class=train_images_label,\n",
    "                          transform=train_transform)\n",
    "\n",
    "val_dataset = MyDataSet(images_path=val_images_path,\n",
    "                        images_class=val_images_label,\n",
    "                        transform=val_transform)\n",
    "\n",
    "# =============================== DataLoader ===============================\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=num_workers)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         pin_memory=True,\n",
    "                                         num_workers=num_workers)\n",
    "\n",
    "print(\"len(train_loader) = {}\".format(len(train_loader)))\n",
    "print(\"len(val_loader) = {}\".format(len(val_loader)))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-25T14:04:14.493718Z",
     "iopub.execute_input": "2023-11-25T14:04:14.495512Z",
     "iopub.status.idle": "2023-11-25T14:04:16.391823Z",
     "shell.execute_reply.started": "2023-11-25T14:04:14.495484Z",
     "shell.execute_reply": "2023-11-25T14:04:16.390815Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": "{'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}\n3670 images were found in the dataset.\n2939 images for training.\n731 images for validation.\nlen(train_loader) = 184\nlen(val_loader) = 46\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class RunningAverage():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.steps = 0\n",
    "        self.loss_sum = 0\n",
    "        self.acc_sum = 0\n",
    "    \n",
    "    def update(self, loss, acc):\n",
    "        self.loss_sum += loss\n",
    "        self.acc_sum += acc\n",
    "        self.steps += 1\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.loss_sum/float(self.steps), self.acc_sum/float(self.steps)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-25T14:04:16.394444Z",
     "iopub.execute_input": "2023-11-25T14:04:16.395129Z",
     "iopub.status.idle": "2023-11-25T14:04:16.401649Z",
     "shell.execute_reply.started": "2023-11-25T14:04:16.395089Z",
     "shell.execute_reply": "2023-11-25T14:04:16.400475Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, train_dataloader, val_dataloader, criteria, optimizer, scheduler, epochs, save_steps):\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, epochs))\n",
    "\n",
    "        # ---------- train ------------\n",
    "        \n",
    "        model.train()\n",
    "        metric_avg = RunningAverage()\n",
    "        \n",
    "        for i, (train_batch, labels_batch) in enumerate(train_dataloader):\n",
    "\n",
    "            train_batch, labels_batch = train_batch.to(device), labels_batch.to(device)\n",
    "            output_batch = model(train_batch)\n",
    "            loss = criteria(output_batch, labels_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if i % save_steps == 0:\n",
    "                output_batch = output_batch.data.cpu().numpy()\n",
    "                labels_batch = labels_batch.data.cpu().numpy()\n",
    "\n",
    "                predict_labels = np.argmax(output_batch, axis=1)\n",
    "                acc = np.sum(predict_labels == labels_batch) / float(labels_batch.size)\n",
    "\n",
    "                metric_avg.update(loss.item(), acc)\n",
    "            \n",
    "        scheduler.step()\n",
    "        train_loss, train_acc = metric_avg()\n",
    "        print(\"- Train metrics: loss={}, acc={}\".format(train_loss, train_acc))      \n",
    "        \n",
    "        \n",
    "\n",
    "        # ---------- validate ------------\n",
    "        model.eval()\n",
    "        metric_avg = RunningAverage()\n",
    "\n",
    "        for val_batch, labels_batch in val_dataloader:\n",
    "            val_batch, labels_batch = val_batch.to(device), labels_batch.to(device)\n",
    "\n",
    "            output_batch = model(val_batch)\n",
    "            loss = criteria(output_batch, labels_batch)\n",
    "\n",
    "            output_batch = output_batch.data.cpu().numpy()\n",
    "            labels_batch = labels_batch.data.cpu().numpy()\n",
    "\n",
    "            predict_labels = np.argmax(output_batch, axis=1)\n",
    "            acc = np.sum(predict_labels == labels_batch) / float(labels_batch.size)\n",
    "\n",
    "            metric_avg.update(loss.item(), acc)\n",
    "\n",
    "        val_loss, val_acc = metric_avg()\n",
    "        print(\"- Validate metrics: loss={}, acc={}\".format(val_loss, val_acc))\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-25T14:04:16.403113Z",
     "iopub.execute_input": "2023-11-25T14:04:16.403570Z",
     "iopub.status.idle": "2023-11-25T14:04:16.417834Z",
     "shell.execute_reply.started": "2023-11-25T14:04:16.403533Z",
     "shell.execute_reply": "2023-11-25T14:04:16.416763Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "resnet34 = nn.Sequential(models.resnet34(),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Dropout(0.5),\n",
    "                         nn.Linear(in_features=1000, out_features=5, bias=True))\n",
    "\n",
    "resnet34.to(device)\n",
    "\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet34.parameters(), lr=lr, momentum=0.9)\n",
    "scheduler = StepLR(optimizer, step_size=lr_step_size, gamma=0.1)\n",
    "\n",
    "train_and_evaluate(resnet34, train_loader, val_loader, criteria, optimizer, scheduler, epochs, save_steps)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-25T14:04:16.419115Z",
     "iopub.execute_input": "2023-11-25T14:04:16.419669Z",
     "iopub.status.idle": "2023-11-25T14:05:16.737088Z",
     "shell.execute_reply.started": "2023-11-25T14:04:16.419643Z",
     "shell.execute_reply": "2023-11-25T14:05:16.735338Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch 1/50\n- Train metrics: loss=1.566262176162318, acc=0.2730263157894737\n- Validate metrics: loss=1.3148392542548801, acc=0.44540513833992096\nEpoch 2/50\n- Train metrics: loss=1.2715342484022443, acc=0.45394736842105265\n- Validate metrics: loss=1.1247641573781553, acc=0.5295207509881423\nEpoch 3/50\n",
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 16\u001B[0m\n\u001B[1;32m     13\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mSGD(resnet34\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mlr, momentum\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.9\u001B[39m)\n\u001B[1;32m     14\u001B[0m scheduler \u001B[38;5;241m=\u001B[39m StepLR(optimizer, step_size\u001B[38;5;241m=\u001B[39mlr_step_size, gamma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m)\n\u001B[0;32m---> 16\u001B[0m \u001B[43mtrain_and_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresnet34\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriteria\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_steps\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[5], line 21\u001B[0m, in \u001B[0;36mtrain_and_evaluate\u001B[0;34m(model, train_dataloader, val_dataloader, criteria, optimizer, scheduler, epochs, save_steps)\u001B[0m\n\u001B[1;32m     17\u001B[0m metric_avg \u001B[38;5;241m=\u001B[39m RunningAverage()\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (train_batch, labels_batch) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_dataloader):\n\u001B[0;32m---> 21\u001B[0m     train_batch, labels_batch \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_batch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m, labels_batch\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     22\u001B[0m     output_batch \u001B[38;5;241m=\u001B[39m model(train_batch)\n\u001B[1;32m     23\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criteria(output_batch, labels_batch)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ]
  }
 ]
}
