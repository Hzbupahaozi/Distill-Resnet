{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 7019145,
     "sourceType": "datasetVersion",
     "datasetId": 4036075
    }
   ],
   "dockerImageVersionId": 30588,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2023-11-24T10:00:39.062936Z",
     "iopub.execute_input": "2023-11-24T10:00:39.063290Z",
     "iopub.status.idle": "2023-11-24T10:00:40.634228Z",
     "shell.execute_reply.started": "2023-11-24T10:00:39.063262Z",
     "shell.execute_reply": "2023-11-24T10:00:40.633169Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "epochs = 20\n",
    "batch_size = 16\n",
    "save_steps = 10\n",
    "num_workers = 4\n",
    "lr = 0.001\n",
    "lr_step = 10"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-24T10:00:40.639228Z",
     "iopub.execute_input": "2023-11-24T10:00:40.639494Z",
     "iopub.status.idle": "2023-11-24T10:00:40.644088Z",
     "shell.execute_reply.started": "2023-11-24T10:00:40.639471Z",
     "shell.execute_reply": "2023-11-24T10:00:40.643265Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class RunningAverage():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.steps = 0\n",
    "        self.loss_sum = 0\n",
    "        self.acc_sum = 0\n",
    "    \n",
    "    def update(self, loss, acc):\n",
    "        self.loss_sum += loss\n",
    "        self.acc_sum += acc\n",
    "        self.steps += 1\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.loss_sum/float(self.steps), self.acc_sum/float(self.steps)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-24T10:00:40.645377Z",
     "iopub.execute_input": "2023-11-24T10:00:40.645790Z",
     "iopub.status.idle": "2023-11-24T10:00:40.656252Z",
     "shell.execute_reply.started": "2023-11-24T10:00:40.645755Z",
     "shell.execute_reply": "2023-11-24T10:00:40.655549Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "def save_checkpoint(state):\n",
    "    \n",
    "    save_dir = \"pretrained_tm_weights\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "        \n",
    "    filepath = os.path.join(save_dir, 'best.pth')\n",
    "    torch.save(state, filepath)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-24T10:00:40.658338Z",
     "iopub.execute_input": "2023-11-24T10:00:40.658650Z",
     "iopub.status.idle": "2023-11-24T10:00:40.670239Z",
     "shell.execute_reply.started": "2023-11-24T10:00:40.658626Z",
     "shell.execute_reply": "2023-11-24T10:00:40.669575Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "def read_split_data(root, val_rate=0.2):\n",
    "    \n",
    "    assert os.path.exists(root), \"dataset root: {} does not exist.\".format(root)\n",
    "\n",
    "    flower_class = [cla for cla in os.listdir(root) if os.path.isdir(os.path.join(root, cla))]\n",
    "    flower_class.sort()\n",
    "    class_indices = dict((k, v) for v, k in enumerate(flower_class))\n",
    "    print(class_indices) \n",
    "\n",
    "    train_images_path = []\n",
    "    train_images_label = []\n",
    "    val_images_path = []\n",
    "    val_images_label = []\n",
    "    every_class_num = []\n",
    "   \n",
    "    for cla in flower_class:\n",
    "        cla_path = os.path.join(root, cla)\n",
    "        images = [os.path.join(root, cla, i) for i in os.listdir(cla_path)]\n",
    "        images.sort()\n",
    "        image_class = class_indices[cla]\n",
    "        \n",
    "        every_class_num.append(len(images))\n",
    "        val_path = random.sample(images, k=int(len(images) * val_rate))\n",
    "        \n",
    "        # 划分训练集 和 验证集\n",
    "        for img_path in images:\n",
    "            if img_path in val_path:  \n",
    "                val_images_path.append(img_path)\n",
    "                val_images_label.append(image_class)\n",
    "            else:  \n",
    "                train_images_path.append(img_path)\n",
    "                train_images_label.append(image_class)\n",
    "\n",
    "    print(\"{} images were found in the dataset.\".format(sum(every_class_num)))\n",
    "    print(\"{} images for training.\".format(len(train_images_path)))\n",
    "    print(\"{} images for validation.\".format(len(val_images_path)))\n",
    "    assert len(train_images_path) > 0, \"number of training images must greater than 0.\"\n",
    "    assert len(val_images_path) > 0, \"number of validation images must greater than 0.\"\n",
    "\n",
    "    return train_images_path, train_images_label, val_images_path, val_images_label\n",
    "\n",
    "\n",
    "class MyDataSet(Dataset):\n",
    "    \"\"\"自定义数据集\"\"\"\n",
    "\n",
    "    def __init__(self, images_path, images_class, transform=None):\n",
    "        self.images_path = images_path\n",
    "        self.images_class = images_class\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_path)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img = Image.open(self.images_path[item])\n",
    "        label = self.images_class[item]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return torch.as_tensor(img), torch.as_tensor(label)\n",
    "\n",
    "\n",
    "data_root = \"/kaggle/input/flowers/flower_photos\"\n",
    "train_images_path, train_images_label, val_images_path, val_images_label = read_split_data(data_root)\n",
    "\n",
    "# =============================== Transform ===============================\n",
    "img_size = 224\n",
    "train_transform = transforms.Compose([transforms.RandomResizedCrop(img_size),\n",
    "                                        transforms.RandomHorizontalFlip(),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "val_transform = transforms.Compose([transforms.Resize(int(img_size * 1.143)),\n",
    "                                      transforms.CenterCrop(img_size),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "# =============================== DataSet ===============================\n",
    "\n",
    "train_dataset = MyDataSet(images_path=train_images_path,\n",
    "                          images_class=train_images_label,\n",
    "                          transform=train_transform)\n",
    "\n",
    "val_dataset = MyDataSet(images_path=val_images_path,\n",
    "                        images_class=val_images_label,\n",
    "                        transform=val_transform)\n",
    "\n",
    "# =============================== DataLoader ===============================\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           pin_memory=True,\n",
    "                                           num_workers=num_workers)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         pin_memory=True,\n",
    "                                         num_workers=num_workers)\n",
    "\n",
    "print(\"len(train_loader) = {}\".format(len(train_loader)))\n",
    "print(\"len(val_loader) = {}\".format(len(val_loader)))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-24T10:00:40.671589Z",
     "iopub.execute_input": "2023-11-24T10:00:40.672144Z",
     "iopub.status.idle": "2023-11-24T10:00:40.987142Z",
     "shell.execute_reply.started": "2023-11-24T10:00:40.672112Z",
     "shell.execute_reply": "2023-11-24T10:00:40.986068Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, train_dataloader, val_dataloader, criteria, optimizer, scheduler, epochs, save_steps):\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, epochs))\n",
    "\n",
    "        # ---------- train ------------\n",
    "        \n",
    "        model.train()\n",
    "        metric_avg = RunningAverage()\n",
    "        \n",
    "        for i, (train_batch, labels_batch) in enumerate(train_dataloader):\n",
    "\n",
    "            train_batch, labels_batch = train_batch.to(device), labels_batch.to(device)\n",
    "            output_batch = model(train_batch)\n",
    "            loss = criteria(output_batch, labels_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if i % save_steps == 0:\n",
    "                output_batch = output_batch.data.cpu().numpy()\n",
    "                labels_batch = labels_batch.data.cpu().numpy()\n",
    "\n",
    "                predict_labels = np.argmax(output_batch, axis=1)\n",
    "                acc = np.sum(predict_labels == labels_batch) / float(labels_batch.size)\n",
    "\n",
    "                metric_avg.update(loss.item(), acc)\n",
    "            \n",
    "        scheduler.step()\n",
    "        train_loss, train_acc = metric_avg()\n",
    "        print(\"- Train metrics: loss={:.2f}, acc={:.2f}\".format(train_loss, train_acc))      \n",
    "        \n",
    "        \n",
    "\n",
    "        # ---------- validate ------------\n",
    "        model.eval()\n",
    "        metric_avg = RunningAverage()\n",
    "\n",
    "        for val_batch, labels_batch in val_dataloader:\n",
    "            val_batch, labels_batch = val_batch.to(device), labels_batch.to(device)\n",
    "\n",
    "            output_batch = model(val_batch)\n",
    "            loss = criteria(output_batch, labels_batch)\n",
    "\n",
    "            output_batch = output_batch.data.cpu().numpy()\n",
    "            labels_batch = labels_batch.data.cpu().numpy()\n",
    "\n",
    "            predict_labels = np.argmax(output_batch, axis=1)\n",
    "            acc = np.sum(predict_labels == labels_batch) / float(labels_batch.size)\n",
    "\n",
    "            metric_avg.update(loss.item(), acc)\n",
    "\n",
    "        val_loss, val_acc = metric_avg()\n",
    "        print(\"- Validate metrics: loss={:.2f}, acc={:.2f}\".format(val_loss, val_acc))\n",
    "\n",
    "\n",
    "        # ---------- Save weights ------------\n",
    "        \n",
    "        is_best = val_acc >= best_val_acc\n",
    "        if is_best:\n",
    "            print(\"- Found new best accuracy\")\n",
    "            best_val_acc = val_acc\n",
    "        \n",
    "            save_checkpoint({'epoch': epoch + 1,\n",
    "                             'state_dict': model.state_dict(),\n",
    "                             'optim_dict' : optimizer.state_dict()})\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-24T10:00:40.988647Z",
     "iopub.execute_input": "2023-11-24T10:00:40.989054Z",
     "iopub.status.idle": "2023-11-24T10:00:41.004314Z",
     "shell.execute_reply.started": "2023-11-24T10:00:40.989018Z",
     "shell.execute_reply": "2023-11-24T10:00:41.003368Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "resnet50 = nn.Sequential(models.resnet50(weights=models.ResNet50_Weights.DEFAULT),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Dropout(0.5),\n",
    "                         nn.Linear(in_features=1000, out_features=5, bias=True))\n",
    "\n",
    "\n",
    "resnet50.to(device)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-24T10:00:41.005610Z",
     "iopub.execute_input": "2023-11-24T10:00:41.006019Z",
     "iopub.status.idle": "2023-11-24T10:00:43.196969Z",
     "shell.execute_reply.started": "2023-11-24T10:00:41.005962Z",
     "shell.execute_reply": "2023-11-24T10:00:43.196030Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet50.parameters(), lr=lr, momentum=0.9)\n",
    "scheduler = StepLR(optimizer, step_size=lr_step, gamma=0.1)\n",
    "\n",
    "train_and_evaluate(resnet50, train_loader, val_loader, criteria, optimizer, scheduler, epochs, save_steps)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-11-24T10:00:43.198186Z",
     "iopub.execute_input": "2023-11-24T10:00:43.198652Z",
     "iopub.status.idle": "2023-11-24T10:11:04.763278Z",
     "shell.execute_reply.started": "2023-11-24T10:00:43.198619Z",
     "shell.execute_reply": "2023-11-24T10:11:04.762251Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
